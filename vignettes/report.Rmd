---
title: "Report for Coding project 2: linear models for regression and binary classification"
author: "Sixian Zhang, Zaoyi Chi, Hao Wang, Zhaolu Yang"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Report for Coding project 2: linear models for regression and binary classification}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)


#library(LinearModel)

data(spam, package = "ElemStatLearn")
data(SAheart, package = "ElemStatLearn")
data(zip.train, package = "ElemStatLearn")
zip.train <- zip.train[zip.train[,1] %in% c(0,1),]
data(prostate, package = "ElemStatLearn")
data(ozone, package = "ElemStatLearn")

data.list <- list(
  spam = list(
    features = as.matrix(spam[, 1:57]),
    labels = ifelse(spam$spam == "spam", 1, 0),
    is.01 = TRUE
  ),

  SAheart = list(
    features = as.matrix(SAheart[, c(1:4,6:9)]),
    labels = SAheart$chd,
    is.01 = TRUE
  ),

  zip.train = list(
    features = as.matrix(zip.train[, -1]),
    labels = zip.train[, 1],
    is.01 = TRUE
  ),


  prostate = list(features = as.matrix(prostate[, 1:8]),
                  labels = prostate$lpsa,
                  is.01 = FALSE),

  ozone = list(features = as.matrix(ozone[,-1]),
               labels = ozone[, 1],
               is.01 = FALSE)
)

n.folds <- 4L

for (data.name in names(data.list)) {
  data.set <- data.list[[data.name]]
  test.loss.mat <- matrix(0, nrow = 4, ncol = 3)
  
  #Check data type here:
  
  set.seed(2)
  
  fold.vec <- sample(rep(1:n.folds, l = length(data.set$labels)))
  
  penalty.vec <- seq(5, 0.1, by = -0.1)
  
  for (i.fold in (1:n.folds)) {
    train.index <- fold.vec != i.fold
    test.index <- !train.index
    
    x.train <- data.set$features[train.index, ]
    y.train <- data.set$labels[train.index]
    x.test <- data.set$feature[test.index, ]
    y.test <- data.set$labels[test.index]
    
    if (data.set$is.01) {
      # binary data
      earlystopping.list <-
        LMLogisticLossEarlyStoppingCV(x.train, y.train, NULL, 100L #, 0.5)
      L2.list <-
        LMLogisticLossL2CV(x.train, y.train, NULL, penalty.vec)
      
      earlystopping.predict <-
        ifelse(earlystopping.list$predict(x.test) > 0.5, 1, 0)
      L2.predict <- ifelse(L2.list$predict(x.test) > 0.5, 1, 0)
      baseline.predict <- ifelse(mean(y.test) > 0.5 , 1, 0)
      # baseline.predict <- mean(y.test)
      
    } else{
      # regression data
      earlystopping.list <-
        LMSquareLossEarlyStoppingCV(x.train, y.train, NULL, 50L)
      L2.list <- LMSquareLossL2CV(x.train, y.train, NULL, penalty.vec)
      
      earlystopping.predict <- earlystopping.list$predict(x.test)
      L2.predict <- L2.list$predict(x.test)
      baseline.predict <- mean(y.test)
    }
    
    # L2 loss
    earlystopping.loss <- mean((earlystopping.predict - y.test) ^ 2)
    L2.loss <- mean((L2.predict - y.test) ^ 2)
    baseline.loss <- mean((baseline.predict - y.test) ^ 2)
    
    test.loss.mat[i.fold,] = c(earlystopping.loss, L2.loss, baseline.loss)
  }
  # show result
  colnames(test.loss.mat) <- c("Early Stopping", "L2", "Baseline")
  
  test.loss.mat
  
  # plot result
  barplot(
    test.loss.mat,
    main = c("Binary Classification: ", data.name),
    xlab = "mean loss value",
    legend = (rownames(test.loss.mat)),
    beside = TRUE
  )
  
  # Run CV for whole dataset
  if(data.set$is.01){
    # Binary
    model.list <- LMLogisticLossL2CV(data.set$features, data.set$labels, NULL, penalty.vec)
  }else{
    # Regression
    model.list <- LMSquareLossL2CV(data.set$features,data.set$labels,NULL, penalty.vec)
  }
  
  dot.x <- model.list$selected.penalty
  dot.y <- model.list$mean.validation.loss.vec[penalty.vec == model.list$selected.penalty]
  
  matplot(
    y = cbind(model.list$mean.validation.loss.vec, model.list$mean.train.loss.vec),
    x = as.matrix(penalty.vec),
    xlab = "penalty",
    ylab = "mean loss value",
    type = "l",
    lty = 1:2,
    pch = 15,
    col = c(17)
  )
  
  matpoints(x = dot.x,
            y = dot.y,
            col = 2,
            pch = 19)
  legend(
    x = length(penalty.vec),
    0,
    c("Validation loss", "Train loss"),
    lty = 1:2,
    xjust = 1,
    yjust = 0
  )
}


```

## Introduction
For this project we created an R package with C++ code that implements a version of the nearest neighbors algorithm.

Here are some significant formulas that have been used in this function:

$cost/loss functions for each learning algorithm:$

**Manhattan distance: ** **$d(i,j)=\sum_{1}^{n}(|X_1-X_2|+|Y_1-Y_2|)$**

**Nearest neighbor prediction function: ** **$f_{D,k(x)} = \frac{1}{k} \sum_{i\in N_{D,k}}^{n} y_i$**

**The optimal number of neighbors:      ** **$\hat{k} = argmin_{k\in (1,2,...,k_{max})} \frac{1}{F_{max}} \sum_{S=1}^{F_{max}} Error_{Ds}(f_{D,-S,k})$     ** 
  *(as estimated via minimizing the mean validation loss).
  

## Main Function
The purpose of this section is to give users a general information of this package. We will briefly go over the main functions.

```{r}
## Source Code:


```

## Experiments/application
we are going to run our code on the following data sets.

## Data set 1: spam
```{r}

```

### Matrix of loss values
```{r, fig.show='hold', fig.width= 6, fig.height= 6}

```

Comment on difference in accuracy:

### Train/validation loss plot
```{r, fig.show='hold', fig.width= 6, fig.height= 6}

```

The optimal number of neighbors is: 

Compare against NNLearnCV, and comment on whether or not linear models or nearest neighbors is more accurate:

## End of the report